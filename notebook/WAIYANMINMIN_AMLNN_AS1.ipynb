{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5IvyVklbaB5"
      },
      "source": [
        "# Advanced Machine Learning and Neural Networks - Assignment 1\n",
        "\n",
        "## Evaluation of a Pre-trained Convolutional Neural Network on Chest X-ray Data\n",
        "\n",
        "**Student:** Wai Yan Min Min  \n",
        "**Module:** Advanced Machine Learning and Neural Network  \n",
        "**Assessment Weight:** 30%\n",
        "\n",
        "---\n",
        "\n",
        "## Assignment Alignment\n",
        "\n",
        "This notebook is designed to satisfy the four required technical tasks:\n",
        "\n",
        "1. Investigate the architecture of a pre-trained CNN and discuss possible improvements.\n",
        "2. Evaluate model performance on the training dataset using known metrics.\n",
        "3. Compare predicted labels against ground truth using confusion matrices.\n",
        "4. Summarise findings and discuss limitations and future work.\n",
        "\n",
        "It also addresses the module learning outcomes by demonstrating model selection, implementation, optimisation, and interpretation of results.\n",
        "\n",
        "---\n",
        "\n",
        "## Notebook Roadmap\n",
        "\n",
        "1. Environment setup and data access\n",
        "2. Data preparation and label strategy\n",
        "3. Exploratory data analysis\n",
        "4. Model selection and architecture inspection\n",
        "5. Training and optimisation\n",
        "6. Evaluation (training + validation)\n",
        "7. Confusion matrix analysis\n",
        "8. Unlabeled inference on unseen images\n",
        "9. Conclusions and recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDF0jLmgHw_P",
        "outputId": "910a868d-fddf-4446-d392-621372393e15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kagglehub\n",
            "  Downloading kagglehub-1.0.0-py3-none-any.whl.metadata (40 kB)\n",
            "Collecting torch\n",
            "  Downloading torch-2.10.0-2-cp312-none-macosx_11_0_arm64.whl.metadata (31 kB)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.25.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
            "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (10.4.0)\n",
            "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (4.66.5)\n",
            "Requirement already satisfied: seaborn in /opt/anaconda3/lib/python3.12/site-packages (0.13.2)\n",
            "Collecting kagglesdk<1.0,>=0.1.14 (from kagglehub)\n",
            "  Downloading kagglesdk-0.1.15-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from kagglehub) (24.1)\n",
            "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from kagglehub) (6.0.1)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/anaconda3/lib/python3.12/site-packages (from seaborn) (3.9.2)\n",
            "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from kagglesdk<1.0,>=0.1.14->kagglehub) (4.25.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (2025.1.31)\n",
            "Downloading kagglehub-1.0.0-py3-none-any.whl (70 kB)\n",
            "Downloading torch-2.10.0-2-cp312-none-macosx_11_0_arm64.whl (79.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.25.0-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kagglesdk-0.1.15-py3-none-any.whl (160 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy, torch, kagglesdk, torchvision, kagglehub\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.2\n",
            "    Uninstalling sympy-1.13.2:\n",
            "      Successfully uninstalled sympy-1.13.2\n",
            "Successfully installed kagglehub-1.0.0 kagglesdk-0.1.15 sympy-1.14.0 torch-2.10.0 torchvision-0.25.0\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub torch torchvision pandas pillow scikit-learn tqdm seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUxRLuocdH-r",
        "outputId": "14bab12c-8902-41c6-976d-1bd08ab7f229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading to /Users/waiyanminmin/.cache/kagglehub/datasets/ashery/chexpert/1.archive...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 10.7G/10.7G [08:51<00:02, 21.5MB/s]  \n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "[Errno 28] No space left on device",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Download latest version\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m path \u001b[38;5;241m=\u001b[39m kagglehub\u001b[38;5;241m.\u001b[39mdataset_download(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mashery/chexpert\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath to dataset files:\u001b[39m\u001b[38;5;124m\"\u001b[39m, path)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/kagglehub/datasets.py:52\u001b[0m, in \u001b[0;36mdataset_download\u001b[0;34m(handle, path, force_download, output_dir)\u001b[0m\n\u001b[1;32m     50\u001b[0m h \u001b[38;5;241m=\u001b[39m parse_dataset_handle(handle)\n\u001b[1;32m     51\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;241m.\u001b[39mto_url()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m, extra\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mEXTRA_CONSOLE_BLOCK})\n\u001b[0;32m---> 52\u001b[0m resolved_path, _ \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mdataset_resolver(\n\u001b[1;32m     53\u001b[0m     h,\n\u001b[1;32m     54\u001b[0m     path,\n\u001b[1;32m     55\u001b[0m     force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m     56\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_path\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/kagglehub/registry.py:28\u001b[0m, in \u001b[0;36mMultiImplRegistry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m impl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impls):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mis_supported(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m         fails\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtype\u001b[39m(impl)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/kagglehub/resolver.py:35\u001b[0m, in \u001b[0;36mResolver.__call__\u001b[0;34m(self, handle, path, force_download, output_dir)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     17\u001b[0m     handle: T,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     output_dir: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resolves a handle into a path with the requested file(s) and the resource's version number.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m        Some cases where version number might be missing: Competition datasource, API-based models.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     path, version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve(\n\u001b[1;32m     36\u001b[0m         handle,\n\u001b[1;32m     37\u001b[0m         path,\n\u001b[1;32m     38\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m     39\u001b[0m         output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[1;32m     40\u001b[0m     )\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     register_datasource_access(handle, version)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/kagglehub/http_resolver.py:154\u001b[0m, in \u001b[0;36mDatasetHttpResolver._resolve\u001b[0;34m(self, h, path, force_download, output_dir)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# First, we download the archive.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m response \u001b[38;5;241m=\u001b[39m handle_call(\u001b[38;5;28;01mlambda\u001b[39;00m: api_client\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mdataset_api_client\u001b[38;5;241m.\u001b[39mdownload_dataset(r), h)\n\u001b[0;32m--> 154\u001b[0m download_file(response, archive_path, h)\n\u001b[1;32m    156\u001b[0m _extract_archive(archive_path, out_path)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Delete the archive\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/kagglehub/clients.py:202\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(response, out_file, resource_handle, cached_path, extract_auto_compressed_file)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 202\u001b[0m     _download_file(response, out_file, size_read, total_size, hash_object)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hash_object:\n\u001b[1;32m    205\u001b[0m     actual_md5_hash \u001b[38;5;241m=\u001b[39m to_b64_digest(hash_object)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/kagglehub/clients.py:247\u001b[0m, in \u001b[0;36m_download_file\u001b[0;34m(response, out_file, size_read, total_size, hash_object)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(out_file, open_mode) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_content(CHUNK_SIZE):\n\u001b[0;32m--> 247\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m hash_object:\n\u001b[1;32m    249\u001b[0m             hash_object\u001b[38;5;241m.\u001b[39mupdate(chunk)\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"ashery/chexpert\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkP3g3qOdLCO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "DATA_ROOT = \"/kaggle/input/chexpert\"\n",
        "SEED = 42\n",
        "\n",
        "# Reproducibility setup\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "print(\"Data root:\", DATA_ROOT)\n",
        "print(\"Seed:\", SEED)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "871jSw7vhlfv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load CSV\n",
        "train_df = pd.read_csv(\"/kaggle/input/chexpert/train.csv\")\n",
        "valid_df = pd.read_csv(\"/kaggle/input/chexpert/valid.csv\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzD4IKnzmrHw"
      },
      "source": [
        "### Data Path Normalisation\n",
        "\n",
        "The `Path` values in the original CSV files include the prefix `CheXpert-v1.0-small/`, while the downloaded dataset root already points at that directory. If this prefix is not removed, image loading fails due to duplicated folder names in constructed file paths.\n",
        "\n",
        "The next cell cleans both training and validation CSV files to ensure robust and reproducible file access during model training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4MhHtYim67c"
      },
      "outputs": [],
      "source": [
        "# Remove the leading 'CheXpert-v1.0-small/' from Path column\n",
        "train_df[\"Path\"] = train_df[\"Path\"].str.replace(\"CheXpert-v1.0-small/\", \"\")\n",
        "valid_df[\"Path\"] = valid_df[\"Path\"].str.replace(\"CheXpert-v1.0-small/\", \"\")\n",
        "\n",
        "# Save fixed CSV (optional)\n",
        "train_df.to_csv(\"train_fixed.csv\", index=False)\n",
        "valid_df.to_csv(\"valid_fixed.csv\", index=False)\n",
        "\n",
        "TRAIN_CSV = \"train_fixed.csv\"\n",
        "VALID_CSV = \"valid_fixed.csv\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfBhmMdTnClN"
      },
      "source": [
        "### Target Label Selection Strategy\n",
        "\n",
        "CheXpert is a multi-label dataset with 14 diagnostic labels. In this assignment, five clinically meaningful labels are selected:\n",
        "\n",
        "- Atelectasis\n",
        "- Cardiomegaly\n",
        "- Consolidation\n",
        "- Edema\n",
        "- Pleural Effusion\n",
        "\n",
        "This focused subset is a practical trade-off between computational cost and diagnostic diversity. It allows clear analysis of class imbalance, per-label performance differences, and confusion patterns, while keeping training feasible within assignment constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2JTBS6Cdxpx"
      },
      "outputs": [],
      "source": [
        "LABELS = [\n",
        "    \"Atelectasis\",\n",
        "    \"Cardiomegaly\",\n",
        "    \"Consolidation\",\n",
        "    \"Edema\",\n",
        "    \"Pleural Effusion\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAHuABQCd0zG"
      },
      "outputs": [],
      "source": [
        "#Method to create dataset\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class CheXpertDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, labels, transform=None):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "        # Ensure numeric type for all labels\n",
        "        for label in self.labels:\n",
        "            self.df[label] = pd.to_numeric(self.df[label], errors='coerce')  # invalid -> NaN\n",
        "            self.df[label] = self.df[label].fillna(0)  # replace NaN with 0\n",
        "            self.df[label] = self.df[label].replace(-1, 0)  # uncertain -> 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        img_path_str = row[\"Path\"]\n",
        "\n",
        "        img_path = os.path.join(self.root_dir, img_path_str)\n",
        "\n",
        "        # Open image\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Convert label to tensor safely\n",
        "        label = torch.tensor(row[self.labels].to_numpy(dtype=float), dtype=torch.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO2mTL_cd3CT"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7nUzAnhd6Qm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = CheXpertDataset(\n",
        "    TRAIN_CSV, DATA_ROOT, LABELS, train_transform\n",
        ")\n",
        "\n",
        "val_dataset = CheXpertDataset(\n",
        "    VALID_CSV, DATA_ROOT, LABELS, val_transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xu1OU16cLi6"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "\n",
        "This section inspects data schema, sample records, label frequencies, and class balance.\n",
        "\n",
        "Why this matters:\n",
        "- It validates whether preprocessing has been applied correctly.\n",
        "- It highlights class imbalance that may affect optimisation and thresholding.\n",
        "- It supports interpretation of model behaviour later in confusion matrix analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYW4X7GocM_V",
        "outputId": "56a65a8b-9aef-4b8a-ea22-d2c30e400c41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 223414 entries, 0 to 223413\n",
            "Data columns (total 19 columns):\n",
            " #   Column                      Non-Null Count   Dtype  \n",
            "---  ------                      --------------   -----  \n",
            " 0   Path                        223414 non-null  object \n",
            " 1   Sex                         223414 non-null  object \n",
            " 2   Age                         223414 non-null  int64  \n",
            " 3   Frontal/Lateral             223414 non-null  object \n",
            " 4   AP/PA                       191027 non-null  object \n",
            " 5   No Finding                  22381 non-null   float64\n",
            " 6   Enlarged Cardiomediastinum  44839 non-null   float64\n",
            " 7   Cardiomegaly                223414 non-null  float64\n",
            " 8   Lung Opacity                117778 non-null  float64\n",
            " 9   Lung Lesion                 11944 non-null   float64\n",
            " 10  Edema                       223414 non-null  float64\n",
            " 11  Consolidation               223414 non-null  float64\n",
            " 12  Pneumonia                   27608 non-null   float64\n",
            " 13  Atelectasis                 223414 non-null  float64\n",
            " 14  Pneumothorax                78934 non-null   float64\n",
            " 15  Pleural Effusion            223414 non-null  float64\n",
            " 16  Pleural Other               6492 non-null    float64\n",
            " 17  Fracture                    12194 non-null   float64\n",
            " 18  Support Devices             123217 non-null  float64\n",
            "dtypes: float64(14), int64(1), object(4)\n",
            "memory usage: 32.4+ MB\n"
          ]
        }
      ],
      "source": [
        "train_dataset.df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "7qq-JqIzhCxL",
        "outputId": "cefed691-04ca-44f9-89f2-b1cc78ffff2c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_dataset\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"train/patient00002/study2/view1_frontal.jpg\",\n          \"train/patient00003/study1/view1_frontal.jpg\",\n          \"train/patient00002/study1/view1_frontal.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Male\",\n          \"Female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18,\n        \"min\": 41,\n        \"max\": 87,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          87,\n          41\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Frontal/Lateral\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Lateral\",\n          \"Frontal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AP/PA\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No Finding\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Enlarged Cardiomediastinum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cardiomegaly\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lung Opacity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lung Lesion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Edema\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.447213595499958,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Consolidation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pneumonia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Atelectasis\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pneumothorax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pleural Effusion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pleural Other\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fracture\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Support Devices\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-8e0d09b2-5b06-4b16-af28-c69a5ce0379e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Path</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Frontal/Lateral</th>\n",
              "      <th>AP/PA</th>\n",
              "      <th>No Finding</th>\n",
              "      <th>Enlarged Cardiomediastinum</th>\n",
              "      <th>Cardiomegaly</th>\n",
              "      <th>Lung Opacity</th>\n",
              "      <th>Lung Lesion</th>\n",
              "      <th>Edema</th>\n",
              "      <th>Consolidation</th>\n",
              "      <th>Pneumonia</th>\n",
              "      <th>Atelectasis</th>\n",
              "      <th>Pneumothorax</th>\n",
              "      <th>Pleural Effusion</th>\n",
              "      <th>Pleural Other</th>\n",
              "      <th>Fracture</th>\n",
              "      <th>Support Devices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train/patient00001/study1/view1_frontal.jpg</td>\n",
              "      <td>Female</td>\n",
              "      <td>68</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train/patient00002/study2/view1_frontal.jpg</td>\n",
              "      <td>Female</td>\n",
              "      <td>87</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train/patient00002/study1/view1_frontal.jpg</td>\n",
              "      <td>Female</td>\n",
              "      <td>83</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train/patient00002/study1/view2_lateral.jpg</td>\n",
              "      <td>Female</td>\n",
              "      <td>83</td>\n",
              "      <td>Lateral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train/patient00003/study1/view1_frontal.jpg</td>\n",
              "      <td>Male</td>\n",
              "      <td>41</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e0d09b2-5b06-4b16-af28-c69a5ce0379e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e0d09b2-5b06-4b16-af28-c69a5ce0379e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e0d09b2-5b06-4b16-af28-c69a5ce0379e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          Path     Sex  Age Frontal/Lateral  \\\n",
              "0  train/patient00001/study1/view1_frontal.jpg  Female   68         Frontal   \n",
              "1  train/patient00002/study2/view1_frontal.jpg  Female   87         Frontal   \n",
              "2  train/patient00002/study1/view1_frontal.jpg  Female   83         Frontal   \n",
              "3  train/patient00002/study1/view2_lateral.jpg  Female   83         Lateral   \n",
              "4  train/patient00003/study1/view1_frontal.jpg    Male   41         Frontal   \n",
              "\n",
              "  AP/PA  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  \\\n",
              "0    AP         1.0                         NaN           0.0           NaN   \n",
              "1    AP         NaN                         NaN           0.0           1.0   \n",
              "2    AP         NaN                         NaN           0.0           1.0   \n",
              "3   NaN         NaN                         NaN           0.0           1.0   \n",
              "4    AP         NaN                         NaN           0.0           NaN   \n",
              "\n",
              "   Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  Pneumothorax  \\\n",
              "0          NaN    0.0            0.0        NaN          0.0           0.0   \n",
              "1          NaN    0.0            0.0        NaN          0.0           NaN   \n",
              "2          NaN    0.0            0.0        NaN          0.0           NaN   \n",
              "3          NaN    0.0            0.0        NaN          0.0           NaN   \n",
              "4          NaN    1.0            0.0        NaN          0.0           0.0   \n",
              "\n",
              "   Pleural Effusion  Pleural Other  Fracture  Support Devices  \n",
              "0               0.0            NaN       NaN              1.0  \n",
              "1               0.0            NaN       1.0              NaN  \n",
              "2               0.0            NaN       1.0              NaN  \n",
              "3               0.0            NaN       1.0              NaN  \n",
              "4               0.0            NaN       NaN              NaN  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3Y6jsvicTPH",
        "outputId": "e8ebe200-8778-4a8c-a4e8-d3bf0463512e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "6x8ZKsSsqR7P",
        "outputId": "9737f908-d113-4aab-a7f2-99c20fd7ac59"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Atelectasis</th>\n",
              "      <td>33376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cardiomegaly</th>\n",
              "      <td>27000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Consolidation</th>\n",
              "      <td>14783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Edema</th>\n",
              "      <td>52246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pleural Effusion</th>\n",
              "      <td>86187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "Atelectasis         33376\n",
              "Cardiomegaly        27000\n",
              "Consolidation       14783\n",
              "Edema               52246\n",
              "Pleural Effusion    86187\n",
              "dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yes_counts = train_dataset.df[LABELS].eq(1.0).sum()\n",
        "\n",
        "yes_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1bI5fUwegin"
      },
      "outputs": [],
      "source": [
        "labels=train_dataset.labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "MMPC-xMOqXst",
        "outputId": "7eeef429-cdc3-49e9-cbee-83cda74afe14"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Pleural Effusion</th>\n",
              "      <td>86187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Edema</th>\n",
              "      <td>52246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Atelectasis</th>\n",
              "      <td>33376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cardiomegaly</th>\n",
              "      <td>27000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Consolidation</th>\n",
              "      <td>14783</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "Pleural Effusion    86187\n",
              "Edema               52246\n",
              "Atelectasis         33376\n",
              "Cardiomegaly        27000\n",
              "Consolidation       14783\n",
              "dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yes_counts.sort_values(ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "v2u3T7GKqY7Y",
        "outputId": "ca8236b6-f595-4135-9700-a0fe1f47081a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Atelectasis</th>\n",
              "      <td>14.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cardiomegaly</th>\n",
              "      <td>12.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Consolidation</th>\n",
              "      <td>6.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Edema</th>\n",
              "      <td>23.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pleural Effusion</th>\n",
              "      <td>38.58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ],
            "text/plain": [
              "Atelectasis         14.94\n",
              "Cardiomegaly        12.09\n",
              "Consolidation        6.62\n",
              "Edema               23.39\n",
              "Pleural Effusion    38.58\n",
              "dtype: float64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_samples = len(train_dataset.df)\n",
        "\n",
        "yes_percent = (yes_counts / total_samples * 100).round(2)\n",
        "\n",
        "yes_percent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "kwanJfNWqZyl",
        "outputId": "7aa42a5b-ffc0-4942-c89f-ba1026431d3d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "yes_counts.sort_values(ascending=False).plot(kind=\"bar\")\n",
        "plt.ylabel(\"Number of positive samples\")\n",
        "plt.title(\"Label distribution (YES counts)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlD5nlQDmkcY"
      },
      "source": [
        "## Model Selection and Architecture\n",
        "\n",
        "### Chosen Pre-trained CNN\n",
        "\n",
        "This notebook uses **DenseNet-121** pre-trained on **ImageNet** and adapts the classifier head for five-label multi-label chest X-ray classification.\n",
        "\n",
        "### Why DenseNet-121?\n",
        "\n",
        "DenseNet is suitable for this task because:\n",
        "- Dense feature reuse improves gradient flow in deep networks.\n",
        "- It offers strong accuracy with comparatively efficient parameter usage.\n",
        "- It is widely used in medical imaging transfer learning pipelines.\n",
        "\n",
        "### Architecture Improvement Ideas (to be revisited in discussion)\n",
        "\n",
        "1. Replace global threshold `0.5` with per-label threshold tuning.\n",
        "2. Use weighted BCE or focal loss to reduce class-imbalance bias.\n",
        "3. Fine-tune deeper layers progressively instead of full-network training from epoch 1.\n",
        "4. Add learning-rate scheduling and early stopping.\n",
        "5. Compare with more recent backbones (e.g., EfficientNet, ConvNeXt) for performance-efficiency trade-offs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3I5YKt3d9PM"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "def get_densenet(num_classes):\n",
        "    model = models.densenet121(weights=\"IMAGENET1K_V1\")\n",
        "    model.classifier = nn.Linear(\n",
        "        model.classifier.in_features, num_classes\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DmERTBTd_P3",
        "outputId": "93409cde-d90a-4093-b7c1-1cd38e28362e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 235MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = get_densenet(len(LABELS)).to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Architecture Inspection\n",
        "\n",
        "The following diagnostic cell reports parameter counts and prints the adapted classifier head. This helps justify model complexity and supports architecture-level discussion in the report and presentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_trainable_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def count_total_params(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(\"Model:\", model.__class__.__name__)\n",
        "print(\"Classifier head:\", model.classifier)\n",
        "print(f\"Total parameters: {count_total_params(model):,}\")\n",
        "print(f\"Trainable parameters: {count_trainable_params(model):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimisation Setup\n",
        "\n",
        "- **Loss:** `BCEWithLogitsLoss` for multi-label classification.\n",
        "- **Optimizer:** Adam with learning rate `1e-4`.\n",
        "- **Training objective:** Minimise average batch loss over epochs while monitoring validation loss for generalisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d52EeUymeCRm"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_one_epoch(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in tqdm(loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4Xm-KzPeD6A"
      },
      "outputs": [],
      "source": [
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqV5zPFqeFzo",
        "outputId": "099a8aa6-69a6-452f-9801-f60692049524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13964/13964 [21:57<00:00, 10.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3 | Train Loss: 0.3623 | Val Loss: 0.4718\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13964/13964 [21:33<00:00, 10.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/3 | Train Loss: 0.3486 | Val Loss: 0.4750\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13964/13964 [21:30<00:00, 10.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/3 | Train Loss: 0.3426 | Val Loss: 0.4663\n"
          ]
        }
      ],
      "source": [
        "# Model training\n",
        "\n",
        "EPOCHS = 3\n",
        "history = {\"train_loss\": [], \"val_loss\": []}\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss = train_one_epoch(model, train_loader)\n",
        "    val_loss = validate(model, val_loader)\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
        "        f\"Train Loss: {train_loss:.4f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y05Leur-pLPV",
        "outputId": "6334d4a1-ec91-4825-f342-a289186c2c5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating model on validation set...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 15/15 [00:00<00:00, 21.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Scores on Validation Set:\n",
            "  Atelectasis: 0.7659\n",
            "  Cardiomegaly: 0.8171\n",
            "  Consolidation: 0.9313\n",
            "  Edema: 0.8919\n",
            "  Pleural Effusion: 0.9155\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    precision_recall_fscore_support,\n",
        "    confusion_matrix,\n",
        ")\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def collect_predictions(model, loader, threshold=0.5, max_batches=None, desc=\"Evaluating\"):\n",
        "    \"\"\"Collect probabilities, binary predictions, and ground-truth labels.\"\"\"\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels_batch) in enumerate(tqdm(loader, desc=desc)):\n",
        "            if max_batches is not None and batch_idx >= max_batches:\n",
        "                break\n",
        "\n",
        "            images = images.to(device)\n",
        "            logits = model(images)\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()\n",
        "            preds = (probs >= threshold).astype(int)\n",
        "\n",
        "            all_probs.append(probs)\n",
        "            all_preds.append(preds)\n",
        "            all_labels.append(labels_batch.cpu().numpy().astype(int))\n",
        "\n",
        "    all_probs = np.vstack(all_probs)\n",
        "    all_preds = np.vstack(all_preds)\n",
        "    all_labels = np.vstack(all_labels)\n",
        "\n",
        "    return all_probs, all_preds, all_labels\n",
        "\n",
        "\n",
        "def evaluate_multilabel(y_true, y_prob, y_pred, label_names):\n",
        "    \"\"\"Return per-label AUC/Precision/Recall/F1 and macro summaries.\"\"\"\n",
        "    results = []\n",
        "    for i, label_name in enumerate(label_names):\n",
        "        y_t = y_true[:, i]\n",
        "        y_p = y_pred[:, i]\n",
        "\n",
        "        if len(np.unique(y_t)) > 1:\n",
        "            auc = roc_auc_score(y_t, y_prob[:, i])\n",
        "        else:\n",
        "            auc = np.nan\n",
        "\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            y_t, y_p, average=\"binary\", zero_division=0\n",
        "        )\n",
        "\n",
        "        results.append(\n",
        "            {\n",
        "                \"Label\": label_name,\n",
        "                \"AUC\": auc,\n",
        "                \"Precision\": precision,\n",
        "                \"Recall\": recall,\n",
        "                \"F1\": f1,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    metrics_df = pd.DataFrame(results)\n",
        "    macro_summary = metrics_df[[\"AUC\", \"Precision\", \"Recall\", \"F1\"]].mean(numeric_only=True)\n",
        "    return metrics_df, macro_summary\n",
        "\n",
        "\n",
        "def plot_confusion_matrices(y_true, y_pred, label_names, title_prefix=\"\"):\n",
        "    \"\"\"Plot one binary confusion matrix per label.\"\"\"\n",
        "    n_labels = len(label_names)\n",
        "    fig, axes = plt.subplots(1, n_labels, figsize=(4 * n_labels, 4))\n",
        "\n",
        "    if n_labels == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for i, label_name in enumerate(label_names):\n",
        "        cm = confusion_matrix(y_true[:, i], y_pred[:, i], labels=[0, 1])\n",
        "        sns.heatmap(\n",
        "            cm,\n",
        "            annot=True,\n",
        "            fmt=\"d\",\n",
        "            cmap=\"Blues\",\n",
        "            cbar=False,\n",
        "            ax=axes[i],\n",
        "            xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
        "            yticklabels=[\"True 0\", \"True 1\"],\n",
        "        )\n",
        "        axes[i].set_title(f\"{title_prefix}{label_name}\")\n",
        "        axes[i].set_xlabel(\"Predicted\")\n",
        "        axes[i].set_ylabel(\"Actual\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fjrbu-DpUBq",
        "outputId": "2008affe-c66f-42c5-fee7-a13f3b83b830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 15/15 [00:00<00:00, 22.10it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'Atelectasis': np.float64(0.7659090909090909),\n",
              " 'Cardiomegaly': np.float64(0.8170623671155209),\n",
              " 'Consolidation': np.float64(0.9312528267752148),\n",
              " 'Edema': np.float64(0.8919459141681364),\n",
              " 'Pleural Effusion': np.float64(0.9154526767360801)}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Visualise training behaviour\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.plot(history[\"train_loss\"], marker=\"o\", label=\"Train Loss\")\n",
        "plt.plot(history[\"val_loss\"], marker=\"o\", label=\"Validation Loss\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate on TRAINING dataset (assignment requirement)\n",
        "train_prob, train_pred, train_true = collect_predictions(\n",
        "    model,\n",
        "    train_loader,\n",
        "    threshold=0.5,\n",
        "    max_batches=None,\n",
        "    desc=\"Evaluating on training data\",\n",
        ")\n",
        "\n",
        "train_metrics_df, train_macro = evaluate_multilabel(train_true, train_prob, train_pred, LABELS)\n",
        "print(\"Per-label metrics on training data:\")\n",
        "display(train_metrics_df.round(4))\n",
        "print(\"Macro-average (training):\")\n",
        "display(train_macro.round(4))\n",
        "\n",
        "# Evaluate on VALIDATION dataset (unseen labeled data)\n",
        "val_prob, val_pred, val_true = collect_predictions(\n",
        "    model,\n",
        "    val_loader,\n",
        "    threshold=0.5,\n",
        "    max_batches=None,\n",
        "    desc=\"Evaluating on validation data\",\n",
        ")\n",
        "\n",
        "val_metrics_df, val_macro = evaluate_multilabel(val_true, val_prob, val_pred, LABELS)\n",
        "print(\"Per-label metrics on validation data:\")\n",
        "display(val_metrics_df.round(4))\n",
        "print(\"Macro-average (validation):\")\n",
        "display(val_macro.round(4))\n",
        "\n",
        "# Confusion matrices required by assignment (training labels vs ground truth)\n",
        "plot_confusion_matrices(train_true, train_pred, LABELS, title_prefix=\"Train - \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference on Unlabeled Unseen Data\n",
        "\n",
        "To satisfy the requirement for an unlabeled dataset the model has not seen during training, we create an **unlabeled inference set** from validation image paths only (labels are intentionally hidden from the model at inference time).\n",
        "\n",
        "This section demonstrates deployment-style prediction: image input -> predicted probability per label -> binary decision using threshold 0.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class UnlabeledCheXpertDataset(Dataset):\n",
        "    def __init__(self, paths, root_dir, transform=None):\n",
        "        self.paths = paths\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        rel_path = self.paths[idx]\n",
        "        img_path = os.path.join(self.root_dir, rel_path)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, rel_path\n",
        "\n",
        "\n",
        "# Build unlabeled loader from validation paths only\n",
        "unlabeled_paths = valid_df[\"Path\"].tolist()\n",
        "unlabeled_dataset = UnlabeledCheXpertDataset(unlabeled_paths, DATA_ROOT, transform=val_transform)\n",
        "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "\n",
        "model.eval()\n",
        "sample_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, rel_paths in unlabeled_loader:\n",
        "        images = images.to(device)\n",
        "        probs = torch.sigmoid(model(images)).cpu().numpy()\n",
        "        preds = (probs >= 0.5).astype(int)\n",
        "\n",
        "        for pth, prob_vec, pred_vec in zip(rel_paths, probs, preds):\n",
        "            active_labels = [LABELS[i] for i, flag in enumerate(pred_vec) if flag == 1]\n",
        "            sample_predictions.append(\n",
        "                {\n",
        "                    \"Image Path\": pth,\n",
        "                    \"Predicted Labels\": \", \".join(active_labels) if active_labels else \"No positive label\",\n",
        "                    \"Max Probability\": float(np.max(prob_vec)),\n",
        "                }\n",
        "            )\n",
        "\n",
        "        if len(sample_predictions) >= 10:\n",
        "            break\n",
        "\n",
        "sample_pred_df = pd.DataFrame(sample_predictions).head(10)\n",
        "print(\"Sample predictions on unlabeled unseen images:\")\n",
        "display(sample_pred_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discussion and Interpretation\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "1. **Transfer learning is effective:** DenseNet-121 provides strong baseline performance even with limited fine-tuning epochs.\n",
        "2. **Class imbalance affects per-label behaviour:** More frequent labels tend to have more stable metrics than rarer labels.\n",
        "3. **Thresholding matters:** A fixed threshold of 0.5 is simple but may underperform for minority labels.\n",
        "4. **Training vs validation gap should be monitored:** If training metrics are much higher than validation metrics, additional regularisation may be required.\n",
        "\n",
        "### Limitations\n",
        "\n",
        "- Only 3 epochs were used, which may underfit or prevent convergence diagnostics.\n",
        "- Label uncertainty (`-1`) was mapped to `0`; alternative uncertainty handling could improve clinical reliability.\n",
        "- No patient-level split re-validation was done in this notebook.\n",
        "\n",
        "### Recommended Improvements\n",
        "\n",
        "- Perform per-label threshold calibration using validation curves.\n",
        "- Use class-weighted BCE or focal loss for imbalance robustness.\n",
        "- Add learning-rate scheduling, early stopping, and model checkpointing.\n",
        "- Compare DenseNet-121 against at least one alternative backbone.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "This notebook demonstrates end-to-end evaluation of a pre-trained CNN for multi-label chest X-ray classification and satisfies the assignment requirements: model architecture investigation, training-set metric evaluation, confusion matrix comparison with ground truth, and clear result interpretation. The workflow is structured to support both a written report and a professional presentation."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
